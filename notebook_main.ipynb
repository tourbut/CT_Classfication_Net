{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import dataloader\n",
    "import utils\n",
    "\n",
    "from model import generate_model\n",
    "from optimizer import Adam,SGD\n",
    "from train_wrapper import train_epoch\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv(config['DATASET_PATH'])\n",
    "df_dataset = df_dataset.dropna().reset_index(drop=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df_dataset.drop(labels='label',axis=1)\n",
    "Y = df_dataset['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,shuffle=True,stratify=None,random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=dataloader.CTDataset(X_train,y_train)\n",
    "valdata=dataloader.CTDataset(X_test,y_test)\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(traindata , batch_size=4, shuffle=True, sampler = None\n",
    "                              ,num_workers=1,pin_memory = True)\n",
    "val_dataloader = DataLoader(valdata , batch_size=4, shuffle=True, sampler = None\n",
    "                              ,num_workers=1,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyGit\\CT_Classfication_Net\\models\\resnet.py:143: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "config['save_datetime'] = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "model_name = config['model']['model_name']\n",
    "model_depth = config['model']['model_depth']\n",
    "\n",
    "model, _ = generate_model(model_name=model_name,model_depth = model_depth,n_classes=3,resnet_shortcut='B',add_last_fc_num = 0)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model, learning_rate = 0.001)\n",
    "criterion_clf = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 0\n",
      "Epoch: [0][0/4]\t lr: 0.0010000000\tLoss : 1.4482\tAcc : 0.00000\t\n",
      "Epoch: [0][3/4]\t lr: 0.0010000000\tLoss : 0.8938\tAcc : 0.50000\t\n",
      "valid at epoch 0\n",
      "Epoch: [0][0/1]\t Loss : 12022.8906\tAcc : 0.25000\t\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGit\\CT_Classfication_Net\\train_wrapper.py:28\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(device, train_dataloader, valid_dataloader, test_dataloader, model, criterion_clf, optimizer, config, epoch, num_classes)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[0;32m     25\u001b[0m     loss, acc \u001b[39m=\u001b[39m train(device,i,train_dataloader,model,criterion_clf\n\u001b[0;32m     26\u001b[0m                     ,optimizer,train_logger,train_batch_logger)\n\u001b[1;32m---> 28\u001b[0m     val_loss,val_acc \u001b[39m=\u001b[39m validation(device,i,valid_dataloader,model,criterion_clf,valid_logger,num_classes\u001b[39m=\u001b[39;49mnum_classes)\n\u001b[0;32m     31\u001b[0m     \u001b[39m#성능이 향상이 없을 때 learning rate를 감소시킨다\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(val_acc)\n",
      "File \u001b[1;32md:\\MyGit\\CT_Classfication_Net\\validation.py:55\u001b[0m, in \u001b[0;36mvalidation\u001b[1;34m(device, epoch, data_loader, model, criterion, logger, num_classes)\u001b[0m\n\u001b[0;32m     51\u001b[0m labels \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mstack(labels)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     53\u001b[0m metric \u001b[39m=\u001b[39m MulticlassConfusionMatrix(num_classes\u001b[39m=\u001b[39mnum_classes)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 55\u001b[0m ConfusionMatrix \u001b[39m=\u001b[39m metric(pred, labels)\n\u001b[0;32m     57\u001b[0m auroc \u001b[39m=\u001b[39m multiclass_auroc(pred, labels, num_classes\u001b[39m=\u001b[39mnum_classes, average\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, thresholds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     59\u001b[0m roc_metric \u001b[39m=\u001b[39m MulticlassROC(num_classes\u001b[39m=\u001b[39mnum_classes, thresholds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\MyGit\\CT_Classfication_Net\\pymain\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\MyGit\\CT_Classfication_Net\\pymain\\lib\\site-packages\\torchmetrics\\metric.py:245\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_full_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_reduce_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32md:\\MyGit\\CT_Classfication_Net\\pymain\\lib\\site-packages\\torchmetrics\\metric.py:309\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    310\u001b[0m batch_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute()\n\u001b[0;32m    312\u001b[0m \u001b[39m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32md:\\MyGit\\CT_Classfication_Net\\pymain\\lib\\site-packages\\torchmetrics\\metric.py:395\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[0;32m    394\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 395\u001b[0m         update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    396\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    397\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[1;32md:\\MyGit\\CT_Classfication_Net\\pymain\\lib\\site-packages\\torchmetrics\\classification\\confusion_matrix.py:211\u001b[0m, in \u001b[0;36mMulticlassConfusionMatrix.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"Update state with predictions and targets.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \n\u001b[0;32m    206\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m    preds: Tensor with predictions\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    target: Tensor with true labels\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_args:\n\u001b[1;32m--> 211\u001b[0m     _multiclass_confusion_matrix_tensor_validation(preds, target, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index)\n\u001b[0;32m    212\u001b[0m preds, target \u001b[39m=\u001b[39m _multiclass_confusion_matrix_format(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_index)\n\u001b[0;32m    213\u001b[0m confmat \u001b[39m=\u001b[39m _multiclass_confusion_matrix_update(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n",
      "File \u001b[1;32md:\\MyGit\\CT_Classfication_Net\\pymain\\lib\\site-packages\\torchmetrics\\functional\\classification\\confusion_matrix.py:257\u001b[0m, in \u001b[0;36m_multiclass_confusion_matrix_tensor_validation\u001b[1;34m(preds, target, num_classes, ignore_index)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf `preds` have one dimension more than `target`, `preds` should be a float tensor.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    256\u001b[0m \u001b[39mif\u001b[39;00m preds\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m num_classes:\n\u001b[1;32m--> 257\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    258\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf `preds` have one dimension more than `target`, `preds.shape[1]` should be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    259\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m equal to number of classes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m preds\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m:] \u001b[39m!=\u001b[39m target\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m    262\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    263\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf `preds` have one dimension more than `target`, the shape of `preds` should be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    264\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m (N, C, ...), and the shape of `target` should be (N, ...).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes."
     ]
    }
   ],
   "source": [
    "train_epoch(device,train_dataloader,val_dataloader,val_dataloader,model,criterion_clf,optimizer,config,epoch = 1,num_classes=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('pymain': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9505ef627af6220152965c2d08f672d4cb1c6e7dfcbb3c78c3906b0b60f7fde3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
